---
title: "Stat 897 Spring 2017 Data Analysis Assignment 3"
author: "Penn State"
date: "Due September 10, 2017"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The goal of this DA assignment will be to familiarize you with linear models and assessing models, as well as beginning to think about model selection.

### 1. (a) Using the dataset ``Auto`` from the ISLR package produce simple summaries of the variables in the data. Plot a couple variables against each other where you think one may be a good predictor of the other.

```{r}
set.seed(243)
library(ISLR)
data(Auto)
attach(Auto)
str(Auto)
summary(Auto)
cor(Auto[1:8])

Auto$cylinders <- as.factor(Auto$cylinders)
Auto$year <- as.factor(Auto$year)
Auto$origin <- as.factor(Auto$origin)
```
We see high correlations between 

mpg and weight: -0.8322442

mpg and displacement: -0.8051269

mpg and horsepower: -0.7784268

We also see very high correlation between:

displacement and cylinders: 0.9508233

weight and cylinders: 0.8975273

weight and displacement: 0.9329944

weight and horsepower: 0.8645377

displacement and horsepower: 0.8972570

Let's plot the pairs to validate followed by plotting some of these variables

```{r}
pairs(Auto)
```

Some of the plots that are of potential interest are:
```{r}
plot(weight, displacement)
plot(weight, horsepower)

plot(mpg, weight)
plot(mpg, displacement)
plot(mpg, horsepower)


```

### (b) Fit a simple linear model using the two variables you chose and produce a summary of the model.

Let's fit a model between mpg and weight
```{r}
lm.fit <- lm(mpg ~ weight, data = Auto)
summary(lm.fit)

```


### (c) Give a 95% confidence interval for the coefficients. Do you think variables are related? Why or why not?

The 95% confidence interval are:

- For the slope it is the estimated coefficient (-0.007647) ± two standard errors (0.000258) = (44.619178, 47.81387)
- For the intercept it is the estimated coefficient (46.216524) ± two standard errors (0.798673) = (-0.008163, -0.007131)

Lets also see how we can generate this using R
```{r}
confint(lm.fit, level = 0.95)
```


### (d) Plot the residuals from your model against the fitted values and comment on anything that looks unusual. (Hint: use the plot.lm function with which = 1.)

```{r}
plot(lm.fit, which = 1)
```

We can observe the following from the plots:

- Non-constant error variance shows up on a residuals vs. fits - the plot has a "fanning" effect where the residuals are close to 0 for small x values and are more spread out for large x values.

- There is a certain non-linearity in the residuals plot.

- While a few points do look like they are outliers it may be due to the fanning effect of the error variance. Therefore we need further analysis in order to comment about the existence of outliers.



### (e) How might you improve your model? (e.g. transformation or addition of a variable).

We can try multiple things as illustrated below:
- Transform the predictor (log)

- Add more predictors

- Transform the response variable (log)

- Add more predictors


```{r}
lm.fit1 <- lm(mpg ~ log(weight), data = Auto)
summary(lm.fit1)

lm.fit2 <- lm(mpg ~ log(weight)+horsepower+displacement, data = Auto)
summary(lm.fit2)

lm.fit3 <- lm(log(mpg) ~ log(weight), data = Auto)
summary(lm.fit3)

lm.fit4 <- lm(log(mpg) ~ log(weight)+horsepower+displacement, data = Auto)
summary(lm.fit4)
```

We see from the above that in all the steps the model fitted better to the training data. We saw the RSE go down and R2 (also adjusted R2) climb up. 

Lets check the residuals for the new model.
```{r}
plot(lm.fit4, which = 1)
```
We see from the above that the model properties have improved (still room for improvement) in terms addressing the non-linearity and non constant variance seen before.

### 2. (a) Load the ``mlbench`` library and upload the ``BostonHousing`` data. Produce a summary of the variable ``medv``.

```{r}
#install.packages('mlbench')
library(mlbench)
data("BostonHousing")
attach(BostonHousing)
```
### (b) Using ``medv`` as your response variable fit a linear regression model with all othe variables as predictors. Compute the training MSE.

```{r}
lm.fit = lm(medv~., data=BostonHousing)
summary(lm.fit)

lm.predict <- predict(lm.fit)

# 2 diff ways to get to the MSE
mean((BostonHousing$medv - lm.predict)^2)

mse <- function(model) 
    mean(model$residuals^2)

mse(lm.fit)

```

Linear regression MSE = 21.89483

### (c) Now find a good model for predicting ``medv``. Explain your process in choosing the model and why it is a good prediction model. Feel free to use any number of the other variables in the data as predictors.

Let's start from where we left in part b of using all the other variables. 
We will use individual names instead of . notation

The first step is the same as part b. We plot the residuals. 
```{r}
lm.fit1 = lm(medv~crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+b+lstat, data=BostonHousing)
summary(lm.fit1)
plot(lm.fit1, which = 1)
```

We observe some non-linearity and so use log transformation of the response variable
```{r}
lm.fit1 = lm(log(medv)~crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+b+lstat, data=BostonHousing)
summary(lm.fit1)
plot(lm.fit1, which = 1)
```

We still see non-linearity. Lets further add sqrt transformation of lstat

```{r}
lm.fit1 = lm(medv~crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+b+sqrt(lstat), data=BostonHousing)
summary(lm.fit1)
plot(lm.fit1, which = 1)
```

Remove the predictors that are not significant in the result.

```{r}
lm.fit1 = lm(log(medv)~crim+chas+nox+rm+dis+rad+tax+ptratio+b+sqrt(lstat), data=BostonHousing)
summary(lm.fit1)
plot(lm.fit1, which = 1)
```

Let's calculate the MSE of this model:

```{r}
lm.predict1 = exp(predict(lm.fit1))
mean((BostonHousing$medv - lm.predict1)^2)
```
MSE is 17.10186

Another interesting tweak to the model that is not linear progression from the above improvements is to include all the predictors and their pairwise interaction terms:

```{r}
lm.fit2 = lm(medv~.^2, data=BostonHousing)
summary(lm.fit2)
plot(lm.fit2, which = 1)
```

The issue here is that while the R2 has improved there are a lot of parameters that are not significant and can be dropped from the model. For our discussion here the model previous to the last will be used for following exercises i.e.

lm.fit1 = lm(log(medv)~crim+chas+nox+rm+dis+rad+tax+ptratio+b+sqrt(lstat), data=BostonHousing)



### (d) Now let's briefly consider a comparison of neural networks with linear regression. We will use the ``nnet`` package and the function ``nnet``. Using the same data fit a neural network with ``medv`` as response and all other variables as predictors. 

```{r}
library(nnet)
```

### (Note: for the neural network you need to scale the response variable so that all values are between 0 and 1. An easy way to do this is by dividing by the maximum value. When you predict values remember to restore the original scale.) 

```{r}
medv_max = max(medv)
medv_max
```

Since the max for response variable medv is 50, we will divide by this number to scale the variable between 0 and 1

The model is:
```{r}
# Since we are using nnet to perform regression (rather than a classification) problem, set linout=T to tell nnet to use a linear output '
nn.fit <- nnet(medv/medv_max ~ ., data=BostonHousing, size=2, linout=TRUE, skip=TRUE)
nn.predict <- predict(nn.fit)
# scale back the predictions 
nn.predict = nn.predict*medv_max

```
### Compute the training MSE and compare it to the MSE from part (b). 

```{r}
mean((nn.predict - BostonHousing$medv)^2) 
```
We find the following:

Linear regression MSE = 21.89483

NNET regression MSE = 21.67675

### Using the same model you chose in part (c), fit a neural network. Compare the training MSEs between the two.


```{r}
medv_max = max(log(medv))
nn.fit <- nnet(log(medv)/medv_max~crim+chas+nox+rm+dis+rad+tax+ptratio+b+sqrt(lstat), data=BostonHousing, size=2, linout=TRUE, skip=TRUE)
nn.predict <- predict(nn.fit)
# scale back the predictions 
nn.predict = exp(nn.predict*medv_max)
mean((nn.predict - BostonHousing$medv)^2) 
```

Linear regression MSE is 17.10186

NNET regression MSE = 16.75603

Finally submit BOTH your .rmd file and the resulting .pdf file with Canvas as Data Analysis Assignment 3.