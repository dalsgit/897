q1.boot
q3.fn=function (data,index){
q = quantile(data[index]);
return (q[4])
}
q3.boot <- boot(Boston$medv, q3.fn, R=1000)
q3.boot
set.seed(3)
head(Auto)
dim(Auto)
train = sample(392, 196)
attach(Auto)
train.error=rep (0,10)
test.error=rep (0,10)
for (i in 1:10){
lm.fit = lm(mpg ~ poly(displacement + horsepower + weight + acceleration, i), data=Auto, subset=train)
train.error[i] = mean((mpg - predict (lm.fit, Auto))[train ]^2)
test.error[i] = mean((mpg - predict (lm.fit, Auto))[-train ]^2)
}
train.error
test.error
plot(x = 1:10, y = train.error, type='b',xlab = "Flexibility - Polynomial Degree", ylab = "Training Error", main = "Training error keeps going down")
plot(x = 1:10, y = test.error, type='b',xlab = "Flexibility - Polynomial Degree", ylab = "Testing Error", main = "Bias / Variance Tradeoff")
plot(x = 1:10, y = train.error, type='b',xlab = "Flexibility - Polynomial Degree", ylab = "Error", col="grey", ylim=c(14,21))
lines(x = 1:10, y = test.error, type='b', col='red')
legend('topright', c('training', 'testing') ,
lty=1, col=c('grey', 'red'), bty='n', cex=.75)
head(Auto)
dim(Auto)
set.seed(3)
head(Auto)
dim(Auto)
train = sample(392, 196)
attach(Auto)
train.error=rep (0,10)
test.error=rep (0,10)
for (i in 1:10){
lm.fit = lm(mpg ~ poly(displacement + horsepower + weight + acceleration, i), data=Auto, subset=train)
train.error[i] = mean((mpg - predict (lm.fit, Auto))[train ]^2)
test.error[i] = mean((mpg - predict (lm.fit, Auto))[-train ]^2)
}
train.error
test.error
plot(x = 1:10, y = train.error, type='b',xlab = "Flexibility - Polynomial Degree", ylab = "Training Error", main = "Training error keeps going down")
plot(x = 1:10, y = test.error, type='b',xlab = "Flexibility - Polynomial Degree", ylab = "Testing Error", main = "Bias / Variance Tradeoff")
setwd("C:\\study\\897\\hw")
library (ISLR)
fix(Hitters )
names(Hitters )
sum(is.na(Hitters$Salary))
source('C:/study/897/hw/rlab_5.r', echo=TRUE)
library (ISLR)
fix(Hitters )
names(Hitters )
data(Hitters )
names(Hitters )
sum(is.na(Hitters$Salary))
Hitters =na.omit(Hitters )
sum(is.na(Hitters$Salary))
set.seed (1)
train=sample (1: nrow(Hitters), nrow(Hitters)/2)
test=(- train )
y.test=y[test]
x=model.matrix (Salary~.,Hitters )[,-1]
y=Hitters$Salary
set.seed (1)
set.seed (1)
train=sample (1: nrow(x), nrow(x)/2)
test=(- train )
y.test=y[test]
grid =10^ seq (10,-2, length =100)
ridge.mod =glmnet (x[train ,],y[train],alpha =0, lambda =grid,
thresh =1e -12)
install.packages('glmnet')
grid =10^ seq (10,-2, length =100)
ridge.mod =glmnet (x[train ,],y[train],alpha =0, lambda =grid,
thresh =1e -12)
ridge.mod =glmnet (x[train ,],y[train],alpha =0, lambda =grid, thresh =1e -12)
ridge.mod =glmnet (x[train ,],y[train],alpha =0, lambda =grid, thresh=1e-12)
library(glmnet)
grid =10^ seq (10,-2, length =100)
grid
ridge.mod =glmnet(x[train ,],y[train],alpha =0, lambda =grid, thresh=1e-12)
ridge.pred=predict (ridge.mod, s=4, newx=x[test ,])
mean(( ridge.pred -y.test)^2)
ridge.pred=predict (ridge.mod, s=50, newx=x[test ,])
mean(( ridge.pred -y.test)^2)
ridge.mod =glmnet (x,y,alpha =0, lambda =grid)
ridge.mod =glmnet (x,y,alpha =0, lambda =grid)
plot(ridge.mod, xvar="lambda", label=T)
cv.out =cv.glmnet (x[train ,],y[train],alpha =0)
plot(cv.out)
bestlam =cv.out$lambda .min
bestlam =cv.out$lambda.min
bestlam
set.seed (1)
cv.out =cv.glmnet (x[train ,],y[train],alpha =0)
plot(cv.out)
bestlam =cv.out$lambda.min
bestlam
source('C:/study/897/hw/rlab_5.r', echo=TRUE)
install.packages("glmnet")
source('C:/study/897/hw/rlab_5.r', echo=TRUE)
set.seed (1)
cv.out =cv.glmnet (x[train ,],y[train],alpha =0)
plot(cv.out)
bestlam =cv.out$lambda.min
bestlam
set.seed (1)
ridge.mod =glmnet(x[train ,],y[train],alpha =0, lambda =grid, thresh=1e-12)
cv.out =cv.glmnet (x[train ,],y[train],alpha =0)
plot(cv.out)
bestlam =cv.out$lambda.min
bestlam
ridge.pred=predict (ridge.mod ,s=bestlam ,newx=x[test ,])
mean(( ridge.pred -y.test)^2)
ridge.pred=predict (ridge.mod ,s=212 ,newx=x[test ,])
mean(( ridge.pred -y.test)^2)
1selam = cvfit$lambda.1se
oneSElam = cvfit$lambda.1se
oneSElam = cv.out$lambda.1se
oneSElam
ridge.pred=predict (ridge.mod ,s=oneSElam ,newx=x[test ,])
mean(( ridge.pred -y.test)^2)
set.seed (1)
ridge.mod =glmnet(x[train ,],y[train],alpha =0, lambda =grid, thresh=1e-12)
cv.out =cv.glmnet (x[train ,],y[train],alpha =0)
plot(cv.out)
bestlam =cv.out$lambda.min
bestlam
ridge.pred=predict (ridge.mod ,s=bestlam ,newx=x[test ,])
mean(( ridge.pred -y.test)^2)
oneSElam = cv.out$lambda.1se
oneSElam
ridge.pred=predict (ridge.mod ,s=oneSElam ,newx=x[test ,])
mean(( ridge.pred -y.test)^2)
lasso.mod =glmnet (x[train ,],y[train],alpha =1, lambda =grid)
plot(lasso.mod)
lasso.mod =glmnet (x[train ,],y[train],alpha =1, lambda =grid)
plot(lasso.mod)
set.seed (1)
cv.out =cv.glmnet (x[train ,],y[train],alpha =1)
plot(cv.out)
bestlam =cv.out$lambda.min
lasso.pred=predict (lasso.mod ,s=bestlam ,newx=x[test ,])
mean(( lasso.pred -y.test)^2)
bestlam
oneSElam = cv.out$lambda.1se
oneSElam
lasso.pred=predict (lasso.mod ,s=oneSElam ,newx=x[test ,])
mean(( lasso.pred -y.test)^2)
lasso.coef[lasso.coef !=0]
out=glmnet (x,y,alpha =1, lambda =grid)
lasso.coef=predict (out ,type =" coefficients",s=oneSElam )[1:20 ,]
lasso.coef=predict (out ,type ="coefficients",s=oneSElam )[1:20 ,]
lasso.coef
lasso.coef[lasso.coef !=0]
knitr::opts_chunk$set(echo = TRUE)
library(ISLR)
data("College")
set.seed (1)
trainingRows=sample (nrow(College), 100, replace = FALSE)
train = College[trainingRows,]
test = College[-trainingRows,]
regfit.best=regsubsets (Apps~.,data=train, nvmax=17)
library(leaps)
regfit.best=regsubsets (Apps~.,data=train, nvmax=17)
test.mat=model.matrix (Apps~.,data=test)
test.val.errors =rep(NA ,17)
for(i in 1:17){
coefi=coef(regfit.best ,id=i)
pred=test.mat [,names(coefi)] %*% coefi
test.val.errors [i]= mean(( test$Apps-pred)^2)
}
plot(test.val.errors ,type='b', xlab='# of parameters', ylab='Test MSE')
train.mat <- model.matrix(Apps ~ ., data = train)
test.mat <- model.matrix(Apps ~ ., data = test)
grid <- 10^seq(4, -2, length = 100)
fit.ridge <- glmnet(train.mat, College.train$Apps, alpha = 0, lambda = grid, thresh = 1e-12)
fit.ridge <- glmnet(train.mat, train$Apps, alpha = 0, lambda = grid, thresh = 1e-12)
cv.ridge <- cv.glmnet(train.mat, train$Apps, alpha = 0, lambda = grid, thresh = 1e-12)
bestlam.ridge <- cv.ridge$lambda.min
bestlam.ridge
grid <- 10^seq(10, -2, length = 100)
fit.ridge <- glmnet(train.mat, train$Apps, alpha = 0, lambda = grid, thresh = 1e-12)
cv.ridge <- cv.glmnet(train.mat, train$Apps, alpha = 0, lambda = grid, thresh = 1e-12)
bestlam.ridge <- cv.ridge$lambda.min
bestlam.ridge
cv.ridge <- cv.glmnet(train.mat, train$Apps, alpha = 0, thresh = 1e-12)
bestlam.ridge <- cv.ridge$lambda.min
bestlam.ridge
x=model.matrix (Apps~.,College )[,-1]
x
x=model.matrix (Apps~.,College )[,-Apps]
x=model.matrix (Apps~.,College )[,-College$Apps]
View(x)
x=model.matrix (Apps~.,College )[,-c(College$Apps)]
x=model.matrix (Apps~.,College )[,-1]
View(x)
x=model.matrix (Apps~.,College )
View(x)
x=model.matrix (Apps~.,College )[,-1]
View(x)
y=College$Apps
y.test=y[test]
y=College$Apps
y.test=y[test]
set.seed (1)
trainingRows=sample (nrow(College), 100, replace = FALSE)
train = College[trainingRows,]
test = College[-trainingRows,]
y.test=y[test]
y[test]
test
y.test=test$Apps
train.mat <- model.matrix(Apps ~ ., data = train)
test.mat <- model.matrix(Apps ~ ., data = test)
cv.ridge <- cv.glmnet(train.mat, train$Apps, alpha = 0)
bestlam.ridge <- cv.ridge$lambda.min
bestlam.ridge
grid =10^ seq (10,-2, length =100)
ridge.mod =glmnet (x[train ,],y[train],alpha =0, lambda =grid, thresh =1e -12)
ridge.mod =glmnet(train.mat, train$Apps, alpha = 0, lambda = grid, thresh = 1e-12)
ridge.mod =glmnet(train.mat, train$Apps, alpha = 0, lambda = grid, thresh = 1e-12)
ridge.pred=predict (ridge.mod, s=bestlam.ridge, newx=test.mat)
mean(( ridge.pred - test$Apps)^2)
which.min(test.val.errors)
test.val.errors
test.val.errors[11]
cv.lasso <- cv.glmnet(train.mat, train$Apps, alpha = 0)
bestlam.ridge <- cv.ridge$lambda.min
cv.lasso <- cv.glmnet(train.mat, train$Apps, alpha = 1)
bestlam.lasso <- cv.lasso$lambda.min
bestlam.lasso
fit.lasso <- glmnet(train.mat, College.train$Apps, alpha = 1, lambda = grid, thresh = 1e-12)
fit.lasso <- glmnet(train.mat, train$Apps, alpha = 1, lambda = grid, thresh = 1e-12)
pred.lasso=predict (fit.lasso, s=bestlam.ridge, newx=test.mat)
mean(( pred.lasso - test$Apps)^2)
pred.lasso=predict (fit.lasso, s=bestlam.lasso, newx=test.mat)
mean(( pred.lasso - test$Apps)^2)
trainingRows=sample (nrow(College), 600, replace = FALSE)
train = College[trainingRows,]
test = College[-trainingRows,]
regfit.best=regsubsets (Apps~.,data=train, nvmax=17)
test.mat=model.matrix (Apps~.,data=test)
test.val.errors =rep(NA ,17)
for(i in 1:17){
coefi=coef(regfit.best ,id=i)
pred=test.mat [,names(coefi)] %*% coefi
test.val.errors [i]= mean(( test$Apps-pred)^2)
}
plot(test.val.errors ,type='b', xlab='# of parameters', ylab='Test MSE')
which.min(test.val.errors)
test.val.errors[11]
train.mat <- model.matrix(Apps ~ ., data = train)
test.mat <- model.matrix(Apps ~ ., data = test)
cv.ridge <- cv.glmnet(train.mat, train$Apps, alpha = 0)
bestlam.ridge <- cv.ridge$lambda.min
bestlam.ridge
fit.ridge =glmnet(train.mat, train$Apps, alpha = 0, lambda = grid, thresh = 1e-12)
pred.ridge = predict (fit.ridge, s=bestlam.ridge, newx=test.mat)
mean(( pred.ridge - test$Apps)^2)
cv.lasso <- cv.glmnet(train.mat, train$Apps, alpha = 1)
bestlam.lasso <- cv.lasso$lambda.min
bestlam.lasso
fit.lasso <- glmnet(train.mat, train$Apps, alpha = 1, lambda = grid, thresh = 1e-12)
pred.lasso=predict (fit.lasso, s=bestlam.lasso, newx=test.mat)
mean(( pred.lasso - test$Apps)^2)
library(quantmod)
load("hw5_spreturns.Rda")
load("hw5_portfolioreturnsstatic.Rda")
View(portfolioreturns)
View(spreturns)
library(quantmod)
load("hw5_spreturns.Rda")
load("hw5_portfolioreturnsstatic.Rda")
View(spreturns)
dim(SPreturns)
dim(spreturns)
dim(portfolioreturns)
total <- merge(portfolioreturns, spreturns)
View(total)
portWithReturns <- merge(portfolioreturns, spreturns, by="ID")
portWithReturns <- cbind(portfolioreturns, spreturns)
View(portWithReturns)
dim(portWithReturns)
dim(spreturns)
names(portWithReturns)
View(portfolioreturns)
lm.fit=lm(..1~., data=portWithReturns)
lm.fit=lm('..1'~., data=portWithReturns)
colnames(portWithReturns)[1] <- "V1"
names(portWithReturns)
lm.fit=lm(V1~., data=portWithReturns)
summary(lm.fit)
port.data <- data.frame(portfolioreturns,spreturns)
View(port.data)
portWithReturnsAndStocks <- cbind(portfolioreturns, spreturns)
dim(portWithReturnsAndStocks)
colnames(portWithReturnsAndStocks)[1] <- "portfolioreturns"
lm.fit=lm(portfolioreturns~., data=portWithReturnsAndStocks)
port.x=model.matrix (portfolioreturns~., portWithReturnsAndStocks)[,-1];
port.y=portWithReturnsAndStocks$portfolioreturns
grid =10^ seq (10,-2, length =100)
port.lasso =glmnet (port.x,port.y,alpha =1, lambda =grid , thresh =1e-12)
plot(port.lasso)
port.ridge =glmnet (port.x,port.y,alpha =0, lambda =grid , thresh =1e-12)
port.ridge
plot(port.ridge)
t = runif(ncol(spreturns))
View(spreturns)
ncol(spreturns)
runif(ncol(spreturns))
thresh = .98
mask = t > thresh
w = runif(ncol(spreturns))
w
w
mask
portfoliowts = w * mask / sum(w * mask)
portfoliowts
sum(mask) # number of chosen coefficients
generateWeightsAndReturns <- function(threshold) {
t = runif(ncol(spreturns))
mask = t > threshold
w = runif(ncol(spreturns))
sum(mask) # number of chosen coefficients
portfoliowts = w * mask / sum(w * mask)
myportfolioreturns = spreturns %*% portfoliowts
}
generateWeightsAndReturns(.98)
generateWeightsAndReturns <- function(threshold) {
t = runif(ncol(spreturns))
mask = t > threshold
w = runif(ncol(spreturns))
sum(mask) # number of chosen coefficients
portfoliowts = w * mask / sum(w * mask)
spreturns %*% portfoliowts
}
generateWeightsAndReturns(.98)
View(portWithReturns)
port.lasso
coef(port.lasso)
unlink('DAA05_cache', recursive = TRUE)
library(quantmod)
load("hw5_spreturns.Rda")
generateWeightsAndReturns <- function(threshold) {
t = runif(ncol(spreturns))
mask = t > threshold
w = runif(ncol(spreturns))
sum(mask) # number of chosen coefficients
portfoliowts = w * mask / sum(w * mask)
spreturns %*% portfoliowts
}
generateWeightsAndReturns(.98)
estimateLassoCoef(generateWeightsAndReturns(.98))
estimateLassoCoef <- function(returns) {
portWithReturnsAndStocks <- cbind(returns, spreturns)
dim(portWithReturnsAndStocks)
colnames(portWithReturnsAndStocks)[1] <- "portfolioreturns"
mat <- model.matrix(portfolioreturns ~ ., data = portWithReturnsAndStocks)
cv.lasso <- cv.glmnet(mat, portWithReturnsAndStocks$portfolioreturns, alpha = 1)
bestlam.lasso <- cv.lasso$lambda.min
bestlam.lasso
fit.lasso <- glmnet(mat, portWithReturnsAndStocks$portfolioreturns, alpha = 1, lambda = grid, thresh = 1e-12)
lasso.coef  <- predict(fit.lasso, type = 'coefficients', s = bestlam)[1:6,]
}
estimateLassoCoef(generateWeightsAndReturns(.98))
wghts = generateWeightsAndReturns(.98)
returns = generateWeightsAndReturns(.98)
portWithReturnsAndStocks <- cbind(returns, spreturns)
View(portWithReturnsAndStocks)
dim(portWithReturnsAndStocks)
dim(portWithReturnsAndStocks)
colnames(portWithReturnsAndStocks)[1] <- "portfolioreturns"
mat <- model.matrix(portfolioreturns ~ ., data = portWithReturnsAndStocks)
View(mat)
cv.lasso <- cv.glmnet(mat, portWithReturnsAndStocks$portfolioreturns, alpha = 1)
bestlam.lasso <- cv.lasso$lambda.min
bestlam.lasso
fit.lasso <- glmnet(mat, portWithReturnsAndStocks$portfolioreturns, alpha = 1, lambda = bestlam.lasso, thresh = 1e-12)
lasso.coef  <- predict(fit.lasso, type = 'coefficients', s = bestlam)[1:6,]
lasso.coef  <- predict(fit.lasso, type = 'coefficients', s = bestlam.lasso)[1:6,]
lasso.coef
lasso.coef  <- predict(fit.lasso, type = 'coefficients', s = bestlam.lasso)
lasso.coef
lasso.coef  <- predict(cv.lasso, type = 'coefficients', s = bestlam.lasso)
lasso.coef
mat <- model.matrix(portfolioreturns ~ ., data = portWithReturnsAndStocks)[-1]
mat <- model.matrix(portfolioreturns ~ ., data = portWithReturnsAndStocks)[-1]
cv.lasso <- cv.glmnet(mat, portWithReturnsAndStocks$portfolioreturns, alpha = 1)
mat <- model.matrix(portfolioreturns ~ ., data = portWithReturnsAndStocks)[,-1]
View(mat)
cv.lasso <- cv.glmnet(mat, portWithReturnsAndStocks$portfolioreturns, alpha = 1)
bestlam.lasso <- cv.lasso$lambda.min
bestlam.lasso
fit.lasso <- glmnet(mat, portWithReturnsAndStocks$portfolioreturns, alpha = 1, lambda = bestlam.lasso, thresh = 1e-12)
lasso.coef  <- predict(cv.lasso, type = 'coefficients', s = bestlam.lasso)
lasso.coef
summary(fit.lasso)
lasso.coef  <- predict(fit.lasso, type = 'coefficients', s = bestlam.lasso)
lasso.coef
estimateLassoCoef(generateWeightsAndReturns(.55))
returns = generateWeightsAndReturns(.98)
portWithReturnsAndStocks <- cbind(returns, spreturns)
dim(portWithReturnsAndStocks)
colnames(portWithReturnsAndStocks)[1] <- "portfolioreturns"
mat <- model.matrix(portfolioreturns ~ ., data = portWithReturnsAndStocks)[,-1]
cv.lasso <- cv.glmnet(mat, portWithReturnsAndStocks$portfolioreturns, alpha = 1)
bestlam.lasso <- cv.lasso$lambda.min
bestlam.lasso
fit.lasso <- glmnet(mat, portWithReturnsAndStocks$portfolioreturns, alpha = 1, lambda = bestlam.lasso, thresh = 1e-12)
summary(fit.lasso)
lasso.coef  <- predict(fit.lasso, type = 'coefficients', s = bestlam.lasso)
lasso.coef
lasso.coef[>1]
dim(cv.lasso)
grid =10^ seq (10,-2, length =100)
mat <- model.matrix(portfolioreturns ~ ., data = portWithReturnsAndStocks)[,-1]
ridge.mod =glmnet (mat, portWithReturnsAndStocks$portfolioreturns, alpha =0, lambda =grid)
dim(coef(ridge.mod ))
ridge.mod$lambda [50]
coef(ridge.mod)[,50]
generateWeightsAndReturns <- function(threshold) {
t = runif(ncol(spreturns))
mask = t > threshold
w = runif(ncol(spreturns))
sum(mask) # number of chosen coefficients
portfoliowts = w * mask / sum(w * mask)
spreturns %*% portfoliowts
}
returns = generateWeightsAndReturns(.98)
View(returns)
t = runif(ncol(spreturns))
thresh = .98
mask = t > thresh
w = runif(ncol(spreturns))
w
sum(mask) # number of chosen coefficients
portfoliowts = w * mask / sum(w * mask)
portfoliowts
View(spreturns)
myportfolioreturns = spreturns %*% portfoliowts
View(myportfolioreturns)
estimateLassoCoef(generateWeightsAndReturns(.98))
returns = generateWeightsAndReturns(.98)
returns = generateWeightsAndReturns(.98)
generateWeightsAndReturns <- function(threshold) {
t = runif(ncol(spreturns))
mask = t > threshold
w = runif(ncol(spreturns))
sum(mask) # number of chosen coefficients
portfoliowts = w * mask / sum(w * mask)
spreturns %*% portfoliowts
}
load("hw5_spreturns.Rda")
returns = generateWeightsAndReturns(.98)
generateWeightsAndReturns <- function(threshold) {
t = runif(ncol(spreturns))
mask = t > threshold
w = runif(ncol(spreturns))
print(sum(mask)) # number of chosen coefficients
portfoliowts = w * mask / sum(w * mask)
spreturns %*% portfoliowts
}
returns = generateWeightsAndReturns(.98)
portWithReturnsAndStocks <- cbind(returns, spreturns)
dim(portWithReturnsAndStocks)
View(portWithReturnsAndStocks)
colnames(portWithReturnsAndStocks)[1] <- "portfolioreturns"
grid =10^ seq (10,-2, length =100)
mat <- model.matrix(portfolioreturns ~ ., data = portWithReturnsAndStocks)[,-1]
View(mat)
cv.lasso <- cv.glmnet(mat, portWithReturnsAndStocks$portfolioreturns, alpha = 1)
dim(cv.lasso)
cv.lasso
cv.lasso
bestlam.lasso <- cv.lasso$lambda.min
bestlam.lasso
ridge.mod =glmnet (x[train ,],y[train],alpha =0, lambda =grid ,thresh =1e -12)
ridge.mod =glmnet (x[train ,],y[train],alpha =0, lambda =grid ,thresh =1e-12)
x=model.matrix (portfolioreturns ~ ., data = portWithReturnsAndStocks)[,-1]
y=portWithReturnsAndStocks$portfolioreturns
train=sample (1: nrow(x), nrow(x)/2)
test=(- train )
grid =10^ seq (10,-2, length =100)
ridge.mod =glmnet (x[train ,],y[train],alpha =0, lambda =grid ,thresh =1e-12)
ridge.pred=predict (ridge.mod ,s=4, newx=x[test ,])
mean(( ridge.pred -y.test)^2)
mean(( ridge.pred -y[test])^2)
mean(( mean(y[train ])-y.test)^2)
mean(( mean(y[train ])-y[test])^2)
ridge.pred=predict (ridge.mod ,s=1e10 ,newx=x[test,])
mean((ridge.pred -y[test])^2)
cv.lasso <- cv.glmnet(x[train ,],y[train], alpha = 1)
plot(cv.lasso)
plot(cv.lasso)
bestlam.lasso <- cv.lasso$lambda.min
bestlam.lasso
plot(cv.lasso)
lasso.pred=predict (lasso.mod ,s=bestlam.lasso ,newx=x[test ,])
lasso.mod =glmnet (x[train ,],y[train],alpha =1, lambda =grid)
plot(lasso.mod)
lasso.mod =glmnet (x,y,alpha =1, lambda =grid)
plot(lasso.mod)
fit.lasso <- glmnet(mat, portWithReturnsAndStocks$portfolioreturns, alpha = 1, thresh = 1e-12)
summary(fit.lasso)
cv.lasso <- cv.glmnet(x[train ,],y[train], alpha = 1)
cv.lasso <- cv.glmnet(x[train ,],y[train], alpha = 1)
plot(cv.lasso)
lasso.mod =glmnet (x[train ,],y[train],alpha =1)
plot(lasso.mod)
